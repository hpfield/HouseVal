{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import copy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('../data/raw/train.csv')\n",
        "test = pd.read_csv('../data/raw/test.csv')\n",
        "print(df.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print missing values in test BsmtFinSF1\n",
        "print(test[test['BsmtFinSF1'].isnull()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print column names that don't match\n",
        "print(set(df.columns) - set(test.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# See if the value 'TenC' appears in the MiscFeature column of either df\n",
        "print('TenC' in df['MiscFeature'].values)\n",
        "print('TenC' in test['MiscFeature'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean(df, enc=None, fit_enc=False):\n",
        "    # One-hot encoding for specified categorical columns\n",
        "    one_hot_columns = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
        "                    'LotConfig', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'MasVnrType', 'Foundation',\n",
        "                    'BsmtFinType1', 'BsmtFinType2', 'GarageFinish', 'Exterior1st', 'Exterior2nd', 'MiscFeature',\n",
        "                    'Heating', 'Electrical', 'GarageType', 'SaleType', 'SaleCondition', 'Neighborhood']\n",
        "    one_hot_df = df[one_hot_columns]\n",
        "    df = df.drop(columns=one_hot_columns)\n",
        "\n",
        "    # Only fit the encoder on the training set to preseve columns in the test set\n",
        "    if fit_enc:\n",
        "        enc.fit(one_hot_df)\n",
        "    one_hot_encoded = enc.transform(one_hot_df)\n",
        "    one_hot_encoded_df = pd.DataFrame(one_hot_encoded, columns=enc.get_feature_names_out(one_hot_columns))\n",
        "    # Reset index on df to avoid issues when concatenating\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    one_hot_encoded_df.reset_index(drop=True, inplace=True)\n",
        "    df = pd.concat([df, one_hot_encoded_df], axis=1)\n",
        "\n",
        "    # Define mappings for each feature\n",
        "    land_slope_mapping = {'Gtl': 1, 'Mod': 2, 'Sev': 3}\n",
        "    heating_qc_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1}\n",
        "    exter_cond_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1}\n",
        "    exter_qual_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1}\n",
        "    kitchen_qual_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1}\n",
        "    fireplace_qu_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}\n",
        "    garage_qual_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}\n",
        "    garage_cond_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}\n",
        "    paved_drive_mapping = {'Y': 2, 'P': 1, 'N': 0}\n",
        "    pool_qc_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'NA': 0}\n",
        "    fence_mapping = {'GdPrv': 4, 'MnPrv': 3, 'GdWo': 2, 'MnWw': 1, 'NA': 0}\n",
        "    functional_mapping = {'Typ': 7, 'Min1': 6, 'Min2': 5, 'Mod': 4, 'Maj1': 3, 'Maj2': 2, 'Sev': 1, 'Sal': 0}\n",
        "    bsmt_qual_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}\n",
        "    bsmt_exposure_mapping = {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NA': 0}\n",
        "    bsmt_cond_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}\n",
        "\n",
        "    # Apply mappings to the dataframe\n",
        "    df['LandSlope'] = df['LandSlope'].map(land_slope_mapping)\n",
        "    df['HeatingQC'] = df['HeatingQC'].map(heating_qc_mapping)\n",
        "    df['ExterCond'] = df['ExterCond'].map(exter_cond_mapping)\n",
        "    df['ExterQual'] = df['ExterQual'].map(exter_qual_mapping)\n",
        "    df['KitchenQual'] = df['KitchenQual'].map(kitchen_qual_mapping)\n",
        "    df['FireplaceQu'] = df['FireplaceQu'].map(fireplace_qu_mapping).fillna(0)  # Assuming NA means no fireplace\n",
        "    df['GarageQual'] = df['GarageQual'].map(garage_qual_mapping).fillna(0)    # Assuming NA means no garage\n",
        "    df['GarageCond'] = df['GarageCond'].map(garage_cond_mapping).fillna(0)    # Assuming NA means no garage\n",
        "    df['PavedDrive'] = df['PavedDrive'].map(paved_drive_mapping)\n",
        "    df['PoolQC'] = df['PoolQC'].map(pool_qc_mapping).fillna(0)                # Assuming NA means no pool\n",
        "    df['Fence'] = df['Fence'].map(fence_mapping).fillna(0)                    # Assuming NA means no fence\n",
        "    df['Functional'] = df['Functional'].map(functional_mapping)\n",
        "    df['BsmtQual'] = df['BsmtQual'].map(bsmt_qual_mapping).fillna(0)  # Assuming NA means no basement\n",
        "    df['BsmtExposure'] = df['BsmtExposure'].map(bsmt_exposure_mapping).fillna(0)  # Assuming NA means no basement\n",
        "    df['BsmtCond'] = df['BsmtCond'].map(bsmt_cond_mapping).fillna(0)  # Assuming NA means no basement\n",
        "\n",
        "    # Combining Condition1 and Condition2 into a combined one-hot\n",
        "    condition1_dummies = pd.get_dummies(df['Condition1'], prefix='Condition')\n",
        "    condition2_dummies = pd.get_dummies(df['Condition2'], prefix='Condition')\n",
        "\n",
        "    # Since we're interested in whether each condition is present regardless of being in Condition1 or Condition2,\n",
        "    # we add the dummies together and clip the values to 1 to ensure binary representation\n",
        "    combined_conditions = condition1_dummies.add(condition2_dummies, fill_value=0).clip(upper=1)\n",
        "    df = df.drop(['Condition1', 'Condition2'], axis=1)\n",
        "    df = df.join(combined_conditions)\n",
        "\n",
        "    # FullBath and BsmtFullBath combined\n",
        "    df['TotalFullBath'] = df['FullBath'] + df['BsmtFullBath']\n",
        "    df.drop(['FullBath', 'BsmtFullBath'], axis=1, inplace=True)\n",
        "\n",
        "    # BsmtHalfBath and HalfBath combined\n",
        "    df['TotalHalfBath'] = df['HalfBath'] + df['BsmtHalfBath']\n",
        "    df.drop(['HalfBath', 'BsmtHalfBath'], axis=1, inplace=True)\n",
        "\n",
        "    # Adding binary features for certain areas\n",
        "    for column in ['WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea']:\n",
        "        df[f'{column}_Present'] = df[column].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "    # GarageYrBlt set missing values to 0\n",
        "    df['GarageYrBlt'].fillna(0, inplace=True)\n",
        "\n",
        "    # Summing square footage features\n",
        "    df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF'] + df['GrLivArea']\n",
        "    df.drop(['TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea'], axis=1, inplace=True)\n",
        "\n",
        "    # Impute LotFrontage with median\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    df['LotFrontage'] = imputer.fit_transform(df[['LotFrontage']])\n",
        "\n",
        "    # MoSold and YrSold to be combined into a single feature\n",
        "    df['SaleDate'] = df['YrSold'] + df['MoSold'] / 12\n",
        "    df.drop(['MoSold', 'YrSold'], axis=1, inplace=True)\n",
        "\n",
        "    # CentralAir is binary\n",
        "    df['CentralAir'] = df['CentralAir'].map({'Y': 1, 'N': 0})\n",
        "\n",
        "    # Convert MasVnrArea null values to 0\n",
        "    df['MasVnrArea'].fillna(0, inplace=True)\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "df = clean(df, enc=encoder, fit_enc=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "missing_values = missing_values[missing_values > 0]\n",
        "print(missing_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for non-numerical columns\n",
        "non_numerical = df.select_dtypes(exclude=['number', 'bool']).columns\n",
        "print(non_numerical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test = clean(test, encoder, False)\n",
        "col_means = test.mean()\n",
        "test.fillna(col_means, inplace=True)\n",
        "test.to_csv('../data/processed/test_cleaned.csv', index=False)\n",
        "missing_values = test.isnull().sum()\n",
        "missing_values = missing_values[missing_values > 0]\n",
        "print(missing_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print the row number of each of the missing values\n",
        "for col in test.columns:\n",
        "    # Find rows where the column is null/NaN\n",
        "    missing_rows = test.index[test[col].isnull()].tolist()\n",
        "    \n",
        "    # Print row numbers (indexes) for missing values, if any\n",
        "    if missing_rows:\n",
        "        print(f\"Missing values in column '{col}': {missing_rows}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print column names that don't match\n",
        "print(set(df.columns) - set(test.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the cleaned dataframe\n",
        "df.to_csv('../data/processed/train_cleaned.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}