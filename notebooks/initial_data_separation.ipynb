{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploratory data analysis\n",
        "\n",
        "Read in and analyse training data, then save important information to JSON file for later use in feature engineering and model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import pandas as pd\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read csv into dataframe\n",
        "data = pd.read_csv('../data/raw/train.csv')\n",
        "data.shape\n",
        "\n",
        "test = pd.read_csv('../data/raw/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(data.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "info = {}\n",
        "info['columns'] = data.columns\n",
        "info['data_types'] = data.dtypes "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "missing_values = data.isnull().sum()\n",
        "print(missing_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "info['missing_values'] = copy.deepcopy(missing_values)\n",
        "rows_with_missing_values = data[data.isnull().any(axis=1)]\n",
        "info['rows_with_missing_values'] = rows_with_missing_values\n",
        "rows_with_missing_values.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Number of cols with missing values\n",
        "missing_values = data.isnull().sum()\n",
        "missing_values = missing_values[missing_values > 0]\n",
        "num_cols_missing_vals = missing_values.shape[0]\n",
        "info['num_cols_missing_vals'] = num_cols_missing_vals\n",
        "num_cols_missing_vals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Editing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### No encoding, just remove cols with missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_cols_with_missing_vals(train, test):\n",
        "    # List cols with missing values in each df, combine the list and remove cols from both\n",
        "    missing_vals_train = train.isnull().sum()\n",
        "    missing_vals_train = missing_vals_train[missing_vals_train > 0]\n",
        "    missing_vals_test = test.isnull().sum()\n",
        "    missing_vals_test = missing_vals_test[missing_vals_test > 0]\n",
        "    cols_to_remove = list(set(missing_vals_train.index) | set(missing_vals_test.index))\n",
        "    _train = train.drop(cols_to_remove, axis=1)\n",
        "    _test = test.drop(cols_to_remove, axis=1)\n",
        "    return _train, _test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### One-Hot-Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def one_hot_encode(train, test):\n",
        "    non_numerical_cols = train.select_dtypes(exclude=['int64', 'float64']).columns\n",
        "    test_non_numerical_cols = test.select_dtypes(exclude=['int64', 'float64']).columns  \n",
        "\n",
        "    # Convert non-numerical columns to one-hot encoding\n",
        "    one_hot_data = pd.get_dummies(train, columns=non_numerical_cols)\n",
        "    one_hot_test = pd.get_dummies(test, columns=test_non_numerical_cols)\n",
        "\n",
        "    # get column names in one_hot_data that are not in one_hot_test\n",
        "    cols_not_in_test = one_hot_data.columns.difference(one_hot_test.columns)\n",
        "\n",
        "    # add clumns to one_hot_test with default value of 0 except for SalePrice\n",
        "    for col in cols_not_in_test:\n",
        "        if col == 'SalePrice':\n",
        "            pass\n",
        "        else:\n",
        "            one_hot_test[col] = 0\n",
        "\n",
        "    return one_hot_data, one_hot_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Impute missing vals with column mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def impute_with_mean(train, test, cols):\n",
        "    # Calculate means for all numerical columns in both dataframes\n",
        "    all_means = pd.concat([\n",
        "        train[cols],\n",
        "        test[cols]\n",
        "    ]).mean()\n",
        "    \n",
        "    # Apply the calculated means to fill missing values in both dataframes\n",
        "    _train = train.copy()\n",
        "    _test = test.copy()\n",
        "    _train[cols] = train[cols].fillna(all_means)\n",
        "    _test[cols] = test[cols].fillna(all_means)\n",
        "    \n",
        "    return _train, _test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def to_categorical(train, test):\n",
        "    # Identify non numerical columns in both dataframes\n",
        "    non_numerical_cols_train = train.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
        "    non_numerical_cols_test = test.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "    # Combine non numerical columns from both dataframes\n",
        "    non_numerical_cols = list(set(non_numerical_cols_train) | set(non_numerical_cols_test))\n",
        "    \n",
        "    # Initialize copies to avoid modifying the original dataframes\n",
        "    _train = train.copy()\n",
        "    _test = test.copy()\n",
        "    \n",
        "    for col in non_numerical_cols:\n",
        "        # Create a mapping from categories to integers for the current column\n",
        "        unique_values_combined = pd.concat([_train[col], _test[col]]).unique()\n",
        "        category_to_int = {value: idx for idx, value in enumerate(unique_values_combined)}\n",
        "        \n",
        "        # Apply the mapping to both dataframes\n",
        "        _train[col] = _train[col].map(category_to_int)\n",
        "        _test[col] = _test[col].map(category_to_int)\n",
        "    \n",
        "    return _train, _test, non_numerical_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def impute_categoricals_with_mode(train, test, categorical_cols):\n",
        "\n",
        "    # Calculate mode for all categorical columns in both dataframes\n",
        "    all_modes = pd.concat([\n",
        "        train[categorical_cols],\n",
        "        test[categorical_cols]\n",
        "    ]).mode().iloc[0]\n",
        "\n",
        "    # Apply the calculated modes to fill missing values in both dataframes\n",
        "    _train = train.copy()\n",
        "    _test = test.copy()\n",
        "    _train[categorical_cols] = train[categorical_cols].fillna(all_modes)\n",
        "    _test[categorical_cols] = test[categorical_cols].fillna(all_modes)\n",
        "\n",
        "    return _train, _test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reorder columns in test df to match order of cols in train\n",
        "def order_test_cols(train, test):\n",
        "    # Get cols in train, omitting SalePrice\n",
        "    train_cols = train.columns.tolist()\n",
        "    train_cols.remove('SalePrice')\n",
        "\n",
        "    # Reorder columns in test to match the order of train\n",
        "    _test = test[train_cols]\n",
        "\n",
        "    return _test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove columns with missing values\n",
        "train_no_missing_vals_cols_removed, test_no_missing_vals_cols_removed = remove_cols_with_missing_vals(data, test)\n",
        "# save the data to csv\n",
        "train_no_missing_vals_cols_removed.to_csv('../data/processed/train_no_missing_vals_cols_removed.csv', index=False)\n",
        "test_no_missing_vals_cols_removed.to_csv('../data/processed/test_no_missing_vals_cols_removed.csv', index=False)\n",
        "print(train_no_missing_vals_cols_removed.shape)\n",
        "print(test_no_missing_vals_cols_removed.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# One Hot Encoded\n",
        "one_hot_data, one_hot_test = one_hot_encode(data, test)\n",
        "\n",
        "# save to csv\n",
        "one_hot_data.to_csv('../data/processed/train_one-hot-encoded.csv', index=False)\n",
        "one_hot_test.to_csv('../data/processed/test_one-hot-encoded.csv', index=False)\n",
        "\n",
        "print(one_hot_data.shape)\n",
        "print(one_hot_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# One Hot Cols Removed\n",
        "one_hot_cols_removed_train, one_hot_cols_removed_test = remove_cols_with_missing_vals(one_hot_data, one_hot_test)\n",
        "\n",
        "one_hot_cols_removed_test = order_test_cols(one_hot_cols_removed_train, one_hot_cols_removed_test)\n",
        "\n",
        "one_hot_cols_removed_train.to_csv('../data/processed/train_one-hot-encoded_no-missing_vals_cols_removed.csv', index=False)\n",
        "one_hot_cols_removed_test.to_csv('../data/processed/test_one-hot-encoded_no-missing_vals_cols_removed.csv', index=False)\n",
        "print(one_hot_cols_removed_train.shape)\n",
        "print(one_hot_cols_removed_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# One Hot Mean Imputed\n",
        "train_one_hot_imputed, test_one_hot_imputed = impute_with_mean(one_hot_data, one_hot_test, one_hot_data.select_dtypes(exclude=['int64', 'float64']).columns.tolist())\n",
        "\n",
        "test_one_hot_imputed = order_test_cols(train_one_hot_imputed, test_one_hot_imputed)\n",
        "\n",
        "# save to csv\n",
        "train_one_hot_imputed.to_csv('../data/processed/train_one-hot-encoded_no-missing_vals_mean_imputed.csv', index=False)\n",
        "test_one_hot_imputed.to_csv('../data/processed/test_one-hot-encoded_no-missing_vals_mean_imputed.csv', index=False)\n",
        "print(train_one_hot_imputed.shape)\n",
        "print(test_one_hot_imputed.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Categorical\n",
        "train_categorical, test_categorical, categorical_cols = to_categorical(data, test)\n",
        "\n",
        "test_categorical = order_test_cols(train_categorical, test_categorical)\n",
        "# save to csv\n",
        "train_categorical.to_csv('../data/processed/train_categorical.csv', index=False)\n",
        "test_categorical.to_csv('../data/processed/test_categorical.csv', index=False)\n",
        "print(train_categorical.shape)\n",
        "print(test_categorical.shape)\n",
        "train_categorical.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Categorical cols removed\n",
        "train_categorical_cols_removed, test_categorical_cols_removed = remove_cols_with_missing_vals(train_categorical, test_categorical)\n",
        "\n",
        "test_categorical_cols_removed = order_test_cols(train_categorical_cols_removed, test_categorical_cols_removed)\n",
        "# save to csv\n",
        "train_categorical_cols_removed.to_csv('../data/processed/train_categorical_no_missing_vals_cols_removed.csv', index=False)\n",
        "test_categorical_cols_removed.to_csv('../data/processed/test_categorical_no_missing_vals_cols_removed.csv', index=False)\n",
        "print(train_categorical_cols_removed.shape)\n",
        "print(test_categorical_cols_removed.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Categorical Mean Imputed\n",
        "train_categorical_imputed, test_categorical_imputed = impute_categoricals_with_mode(train_categorical, test_categorical, categorical_cols)\n",
        "train_categorical_imputed, test_categorical_imputed = impute_with_mean(train_categorical_imputed, test_categorical_imputed, categorical_cols)\n",
        "\n",
        "test_categorical_imputed = order_test_cols(train_categorical_imputed, test_categorical_imputed)\n",
        "\n",
        "# save to csv\n",
        "train_categorical_imputed.to_csv('../data/processed/train_categorical_no_missing_vals_mean_imputed.csv', index=False)\n",
        "test_categorical_imputed.to_csv('../data/processed/test_categorical_no_missing_vals_mean_imputed.csv', index=False)\n",
        "print(train_categorical_imputed.shape)\n",
        "print(test_categorical_imputed.shape)\n",
        "train_categorical_imputed.head()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}